{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 11, 'axes.labelsize': 10, 'axes.titlesize': 16})\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['axes.edgecolor'] = 'black'\n",
    "#plt.rcParams['xtick.color'] = 'black'\n",
    "plt.rcParams['xtick.color'] = 'white'\n",
    "#plt.rcParams['ytick.color'] = 'black'\n",
    "plt.rcParams['ytick.color'] = 'white'\n",
    "plt.rcParams['figure.figsize'] = (22, 11)\n",
    "\n",
    "# Grid with opacity and in background\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.color'] = 'lightgray'\n",
    "plt.rcParams['grid.alpha'] = 0.5\n",
    "plt.rcParams['axes.axisbelow'] = True\n",
    "\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "#plt.rcParams['axes.titlecolor'] = 'black'\n",
    "plt.rcParams['axes.titlecolor'] = 'white'\n",
    "#plt.rcParams['axes.labelcolor'] = 'black'\n",
    "plt.rcParams['legend.labelcolor'] = 'black'\n",
    "plt.rcParams['legend.facecolor'] = 'white'\n",
    "plt.rcParams['legend.edgecolor'] = 'gray'\n",
    "plt.rcParams['text.color'] = 'black'\n",
    "sns.set_palette(\"viridis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set TODAY DATE\n",
    "# today_date = pd.Timestamp.now(tz='UTC')\n",
    "today_date = pd.Timestamp('2025-05-30', tz='UTC')  # For testing purposes\n",
    "\n",
    "\n",
    "# Set REFUND PERDIOD DURATION\n",
    "REFUND_PERIOD_DAYS = 14  # Duration of the refund period in days\n",
    "\n",
    "# Set thresholds for cleaning\n",
    "HIGH_VOLUME_THRESHOLD = 6\n",
    "DUPLICATE_THRESHOLD_MINUTES = 15\n",
    "\n",
    "\n",
    "# Set DIRECTORIES\n",
    "data_dir = 'both_csv_go_here'\n",
    "archive_csv_dir = 'archive/csv'\n",
    "archive_png_dir = 'archive/analysis/png'\n",
    "archive_pdf_dir = 'archive/analysis/pdf'\n",
    "analysis_dir = 'analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ ARCHIVING SUMMARY (2025-06-27 15:49:20):\n",
      "   PNG files transferred: 0\n",
      "   PDF files transferred: 0\n",
      "   Total files archived: 0\n",
      "üóëÔ∏è  No files to clean in analysis directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_file_creation_date(file_path):\n",
    "    \"\"\"\n",
    "    Get the creation date of a file and return it as a formatted string\n",
    "    Returns format: YYYY-MM-DD\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get file creation time (or modification time if creation not available)\n",
    "        if os.name == 'nt':  # Windows\n",
    "            creation_time = os.path.getctime(file_path)\n",
    "        else:  # Unix/Linux/Mac\n",
    "            creation_time = os.path.getmtime(file_path)\n",
    "\n",
    "        # Convert to datetime and format\n",
    "        creation_date = datetime.fromtimestamp(creation_time)\n",
    "        return creation_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error getting creation date for {file_path}: {e}\")\n",
    "        # Fallback to today's date\n",
    "        return datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "def transfer_files_to_archive():\n",
    "    \"\"\"\n",
    "    Enhanced version with date-based organization\n",
    "    Transfer PNG files from analysis_dir to archive_png_dir/YYYY-MM-DD/\n",
    "    Transfer PDF files from analysis_dir to archive_pdf_dir/YYYY-MM-DD/\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # === TRANSFER PNG FILES ===\n",
    "    png_files = glob.glob(os.path.join(analysis_dir, \"*.png\"))\n",
    "    png_transferred = 0\n",
    "\n",
    "    for png_file in png_files:\n",
    "        filename = os.path.basename(png_file)\n",
    "\n",
    "        # Get creation date for organization\n",
    "        creation_date = get_file_creation_date(png_file)\n",
    "\n",
    "        # Create date-based directory in archive\n",
    "        date_archive_dir = os.path.join(archive_png_dir, creation_date)\n",
    "        os.makedirs(date_archive_dir, exist_ok=True)\n",
    "\n",
    "        # Set destination with date organization\n",
    "        destination = os.path.join(date_archive_dir, filename)\n",
    "\n",
    "        try:\n",
    "            # Copy file to archive (keep original in analysis_dir)\n",
    "            shutil.copy2(png_file, destination)\n",
    "            print(f\"üìä PNG archived: {creation_date}/{filename}\")\n",
    "            png_transferred += 1\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error archiving PNG {filename}: {e}\")\n",
    "\n",
    "    # === TRANSFER PDF FILES ===\n",
    "    pdf_files = glob.glob(os.path.join(analysis_dir, \"*.pdf\"))\n",
    "    pdf_transferred = 0\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        filename = os.path.basename(pdf_file)\n",
    "\n",
    "        # Get creation date for organization\n",
    "        creation_date = get_file_creation_date(pdf_file)\n",
    "\n",
    "        # Create date-based directory in archive\n",
    "        date_archive_dir = os.path.join(archive_pdf_dir, creation_date)\n",
    "        os.makedirs(date_archive_dir, exist_ok=True)\n",
    "\n",
    "        # Set destination with date organization\n",
    "        destination = os.path.join(date_archive_dir, filename)\n",
    "\n",
    "        try:\n",
    "            # Copy file to archive (keep original in analysis_dir)\n",
    "            shutil.copy2(pdf_file, destination)\n",
    "            print(f\"üìÑ PDF archived: {creation_date}/{filename}\")\n",
    "            pdf_transferred += 1\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error archiving PDF {filename}: {e}\")\n",
    "\n",
    "    # === SUMMARY ===\n",
    "    print(f\"\\nüì¶ ARCHIVING SUMMARY ({timestamp}):\")\n",
    "    print(f\"   PNG files transferred: {png_transferred}\")\n",
    "    print(f\"   PDF files transferred: {pdf_transferred}\")\n",
    "    print(f\"   Total files archived: {png_transferred + pdf_transferred}\")\n",
    "\n",
    "    return png_transferred, pdf_transferred\n",
    "\n",
    "\n",
    "def clean_analysis_dir_after_archive():\n",
    "    \"\"\"\n",
    "    OPTIONAL: Remove files from analysis_dir after successful archiving\n",
    "    USE WITH CAUTION - This will delete the original files!\n",
    "    Enhanced with better logging and date information\n",
    "    \"\"\"\n",
    "    # Get all PNG and PDF files in analysis_dir\n",
    "    png_files = glob.glob(os.path.join(analysis_dir, \"*.png\"))\n",
    "    pdf_files = glob.glob(os.path.join(analysis_dir, \"*.pdf\"))\n",
    "    all_files = png_files + pdf_files\n",
    "\n",
    "    if not all_files:\n",
    "        print(\"üóëÔ∏è  No files to clean in analysis directory\")\n",
    "        return 0\n",
    "\n",
    "    print(f\"üóëÔ∏è  Cleaning {len(all_files)} files from {analysis_dir}...\")\n",
    "\n",
    "    cleaned_files = 0\n",
    "\n",
    "    for file_path in all_files:\n",
    "        try:\n",
    "            filename = os.path.basename(file_path)\n",
    "            creation_date = get_file_creation_date(file_path)\n",
    "\n",
    "            os.remove(file_path)\n",
    "            print(f\"üóëÔ∏è  Cleaned: {filename} (was from {creation_date})\")\n",
    "            cleaned_files += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error cleaning {file_path}: {e}\")\n",
    "\n",
    "    print(f\"üßπ Cleanup complete: {cleaned_files} files removed from {analysis_dir}\")\n",
    "    return cleaned_files\n",
    "\n",
    "\n",
    "transfer_files_to_archive()\n",
    "clean_analysis_dir_after_archive()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  File 1:\n",
      " DishpatchSubscriptionData_NIklas_Sanitised - subscriptions.csv\n",
      "  File 2:\n",
      " DishpatchInvoiceData_NIklas_Sanitised - invoices.csv\n",
      "\n",
      "Loading CSV files:\n",
      "  File 1: DishpatchSubscriptionData_NIklas_Sanitised - subscriptions.csv\n",
      "  File 2: DishpatchInvoiceData_NIklas_Sanitised - invoices.csv\n",
      "\n",
      "Successfully loaded:\n",
      "  sub_raw: 20443 rows, 34 columns\n",
      "  inv_raw: 33239 rows, 53 columns\n",
      "\n",
      "DataFrames available as: sub_raw, inv_raw\n",
      "\n",
      "Processing complete!\n",
      "***************************************************\n"
     ]
    }
   ],
   "source": [
    "# LOADING CSV\n",
    "\n",
    "# Toggle this flag to True in production\n",
    "RENAME_FILES = False\n",
    "MOVE_FILES = False\n",
    "\n",
    "# Ensure archive directory exists\n",
    "os.makedirs(archive_csv_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# List and sort files by creation time\n",
    "files = [\n",
    "    os.path.join(data_dir, f)\n",
    "    for f in os.listdir(data_dir)\n",
    "    if os.path.isfile(os.path.join(data_dir, f)) and f.endswith('.csv')]\n",
    "sorted_files = sorted(files, key=os.path.getctime, reverse=True)\n",
    "\n",
    "# Check if we have exactly 2 CSV files\n",
    "if len(sorted_files) != 2:\n",
    "    print(f\"Error: Expected 2 CSV files, found {len(sorted_files)}\")\n",
    "    print(\"Files found:\", [os.path.basename(f) for f in sorted_files])\n",
    "    exit(1)\n",
    "\n",
    "for i, file_path in enumerate(sorted_files, 1):\n",
    "    print(f\"  File {i}:\\n {os.path.basename(file_path)}\")\n",
    "\n",
    "# Loop over files\n",
    "processed_files = []\n",
    "for file_path in sorted_files:\n",
    "    created_at = datetime.fromtimestamp(os.path.getctime(file_path))\n",
    "    timestamp_str = created_at.strftime('%Y-%m-%d_%H-%M')\n",
    "    original_name = os.path.basename(file_path)\n",
    "    new_name = f\"{timestamp_str}_{original_name}\"\n",
    "\n",
    "    if RENAME_FILES:\n",
    "        if not original_name.startswith(timestamp_str):\n",
    "            new_path = os.path.join(data_dir, new_name)\n",
    "            os.rename(file_path, new_path)\n",
    "            print(f\"Renamed:\\n {original_name} ‚Üí\\n {new_name}\\n\")\n",
    "            processed_files.append(new_path)\n",
    "        else:\n",
    "            processed_files.append(file_path)\n",
    "    else:\n",
    "        processed_files.append(file_path)\n",
    "\n",
    "# Load both CSV files into pandas DataFrames\n",
    "file1_path, file2_path = processed_files[0], processed_files[1]\n",
    "print(f\"\\nLoading CSV files:\")\n",
    "print(f\"  File 1: {os.path.basename(file1_path)}\")\n",
    "print(f\"  File 2: {os.path.basename(file2_path)}\")\n",
    "\n",
    "try:\n",
    "    sub_raw = pd.read_csv(file1_path, low_memory=False)\n",
    "    inv_raw = pd.read_csv(file2_path, low_memory=False)\n",
    "    print(f\"\\nSuccessfully loaded:\")\n",
    "    print(f\"  sub_raw: {sub_raw.shape[0]} rows, {sub_raw.shape[1]} columns\")\n",
    "    print(f\"  inv_raw: {inv_raw.shape[0]} rows, {inv_raw.shape[1]} columns\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV files: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Move files to archive\n",
    "if MOVE_FILES:\n",
    "    for file_path in processed_files:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        archive_path = os.path.join(archive_csv_dir, file_name)\n",
    "\n",
    "        if not os.path.exists(archive_path):\n",
    "            os.rename(file_path, archive_path)\n",
    "            print(f\"Moved: {file_name} to archive\")\n",
    "        else:\n",
    "            print(f\"Already archived: {file_name}\")\n",
    "else:\n",
    "    for file_path in processed_files:\n",
    "        file_name = os.path.basename(file_path)\n",
    "\n",
    "print(\"\\nDataFrames available as: sub_raw, inv_raw\")\n",
    "print(\"\\nProcessing complete!\")\n",
    "print('***************************************************')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Reference date (TODAY) : 30-05-2025\n",
      "20443 entries loaded from both_csv_go_here/DishpatchInvoiceData_NIklas_Sanitised - invoices.csv\n",
      "***************************************************\n"
     ]
    }
   ],
   "source": [
    "# DATA PREPROCESSING (customer_df)\n",
    "def preprocess_data(input_df):\n",
    "    \"\"\"Clean and preprocess the subscription data\"\"\"\n",
    "    df = input_df.copy()\n",
    "\n",
    "    # Date conversion\n",
    "    date_cols = [col for col in df.columns if '(UTC)' in col]\n",
    "    for col in date_cols:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce', utc=True)\n",
    "\n",
    "    df = df.sort_values(by='Created (UTC)')\n",
    "\n",
    "    # Column selection and renaming\n",
    "    columns_to_keep = [\n",
    "        'id', 'Customer Name', 'Customer ID', 'Status', 'Cancellation Reason',\n",
    "        'Created (UTC)', 'Start (UTC)', 'Current Period Start (UTC)',\n",
    "        'Current Period End (UTC)', 'Trial Start (UTC)', 'Trial End (UTC)',\n",
    "        'Canceled At (UTC)', 'Ended At (UTC)', 'senderShopifyCustomerId (metadata)'\n",
    "    ]\n",
    "\n",
    "    df = df[columns_to_keep]\n",
    "\n",
    "    df.rename(columns={\n",
    "        'id': 'subscription_id',\n",
    "        'Customer ID': 'customer_id',\n",
    "        'Customer Name': 'customer_name',\n",
    "        'Status': 'status',\n",
    "        'Cancellation Reason': 'cancellation_reason',\n",
    "        'Created (UTC)': 'created_utc',\n",
    "        'Start (UTC)': 'start_utc',\n",
    "        'Current Period Start (UTC)': 'current_period_start_utc',\n",
    "        'Current Period End (UTC)': 'current_period_end_utc',\n",
    "        'Trial Start (UTC)': 'trial_start_utc',\n",
    "        'Trial End (UTC)': 'trial_end_utc',\n",
    "        'Canceled At (UTC)': 'canceled_at_utc',\n",
    "        'Ended At (UTC)': 'ended_at_utc',\n",
    "        'senderShopifyCustomerId (metadata)': 'is_gifted_member'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Convert is_gifted_member to boolean\n",
    "    df['is_gifted_member'] = df['is_gifted_member'].notna()\n",
    "\n",
    "\n",
    "    # Reference date for analysis\n",
    "    print(f\"üìÖ Reference date (TODAY) : {today_date.strftime('%d-%m-%Y')}\")\n",
    "    print(f\"{len(df)} entries loaded from {file_path}\")\n",
    "    print('***************************************************')\n",
    "\n",
    "    return df\n",
    "\n",
    "sub_df = preprocess_data(sub_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE ALL MULTI-SUB customer_id from sub_df, put them im a new df multisub_df\n",
    "def remove_multi_subscriptions(df):\n",
    "    \"\"\"Remove customers with multiple subscriptions and return a new DataFrame\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Count subscriptions per customer\n",
    "    subscription_counts = df['customer_id'].value_counts()\n",
    "\n",
    "    # Get customers with more than one subscription\n",
    "    multi_sub_customers = subscription_counts[subscription_counts > 1].index.tolist()\n",
    "\n",
    "    # Filter out these customers from the main DataFrame\n",
    "    single_sub_df = df[~df['customer_id'].isin(multi_sub_customers)]\n",
    "\n",
    "    # Create a new DataFrame for multi-subscription customers\n",
    "    multi_sub_df = df[df['customer_id'].isin(multi_sub_customers)]\n",
    "\n",
    "    print(f\"Removed {len(multi_sub_customers)} customers with multiple subscriptions.\")\n",
    "    print(f\"Total single_sub_df: {len(single_sub_df)}, with {len(single_sub_df['customer_id'].unique())} unique customers\")\n",
    "    print(f\"Total multi_sub_df: {len(multi_sub_df)}, with {len(multi_sub_df['customer_id'].unique())} unique customers\")\n",
    "\n",
    "\n",
    "    return single_sub_df, multi_sub_df\n",
    "\n",
    "\n",
    "#sub_df, multisub_df = remove_multi_subscriptions(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPROCESSING (invoices df)\n",
    "def preprocess_data_invoice(input_df):\n",
    "    \"\"\"Clean and preprocess the subscription data\"\"\"\n",
    "    df = input_df.copy()\n",
    "\n",
    "    # Date conversion\n",
    "    date_cols = [col for col in df.columns if '(UTC)' in col]\n",
    "    for col in date_cols:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce', utc=True)\n",
    "\n",
    "    # Trier par date et par customer ID\n",
    "    df = df.sort_values(['Date (UTC)', 'Customer'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Column selection and renaming\n",
    "    columns_to_keep = [\n",
    "        'id', 'Customer Name', 'Customer', 'Amount Due', 'Amount Paid', 'Paid', 'Billing', 'Charge', 'Closed',\n",
    "        'Date (UTC)', 'Description', 'Number', 'Finalized At (UTC)',\n",
    "        'Paid At (UTC)', 'Minimum Line Item Period Start (UTC)', 'Maximum Line Item Period End (UTC)',\n",
    "        'Period End (UTC)', 'Subscription', 'Total Discount Amount', 'Applied Coupons', 'Status'\n",
    "        ]\n",
    "\n",
    "    df = df[columns_to_keep]\n",
    "\n",
    "    df.rename(columns={\n",
    "        'id': 'invoice_id',\n",
    "        'Status': 'inv_status',\n",
    "        'Customer': 'customer_id',\n",
    "        'Customer Name': 'customer_name',\n",
    "        'Date (UTC)' : 'date_utc',\n",
    "        'Description': 'description',\n",
    "        'Paid': 'paid',\n",
    "        'Paid At (UTC)': 'paid_at_utc',\n",
    "        'Amount Paid': 'amount_paid',\n",
    "        'Subscription': 'subscription_id',\n",
    "    }, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "inv_df = preprocess_data_invoice(inv_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223 subscriptions removed from 23 customers with more than 6 subscriptions\n",
      "***************************************************\n"
     ]
    }
   ],
   "source": [
    "# Removing customers with more than 5 subscriptions (Probably testing accounts)\n",
    "def remove_high_volume_customers(df, threshold=HIGH_VOLUME_THRESHOLD):\n",
    "    \"\"\"Remove customers with more than a specified number of subscriptions\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    original_count = len(df)\n",
    "\n",
    "    customer_counts = df['customer_id'].value_counts()\n",
    "    high_volume_customers = customer_counts[customer_counts > threshold].index\n",
    "\n",
    "    df = df[~df['customer_id'].isin(high_volume_customers)]\n",
    "\n",
    "    print(f'{original_count - len(df)} subscriptions removed from \\\n",
    "{len(high_volume_customers)} customers with more than {threshold} subscriptions')\n",
    "    print('***************************************************')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "inv_df = remove_high_volume_customers(inv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33016\n",
      "33016\n"
     ]
    }
   ],
   "source": [
    "# Drop all rows where 'invoice' is False (or equivalent column if named differently)\n",
    "print(len(inv_df))\n",
    "#inv_df = inv_df[inv_df['paid'] == True]\n",
    "print(len(inv_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invoice_id</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>Amount Due</th>\n",
       "      <th>amount_paid</th>\n",
       "      <th>paid</th>\n",
       "      <th>Billing</th>\n",
       "      <th>Charge</th>\n",
       "      <th>Closed</th>\n",
       "      <th>date_utc</th>\n",
       "      <th>description</th>\n",
       "      <th>Number</th>\n",
       "      <th>Finalized At (UTC)</th>\n",
       "      <th>paid_at_utc</th>\n",
       "      <th>Minimum Line Item Period Start (UTC)</th>\n",
       "      <th>Maximum Line Item Period End (UTC)</th>\n",
       "      <th>Period End (UTC)</th>\n",
       "      <th>subscription_id</th>\n",
       "      <th>Total Discount Amount</th>\n",
       "      <th>Applied Coupons</th>\n",
       "      <th>inv_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18684</th>\n",
       "      <td>in_1PG2bVCZ9aYYH5wi149OP50H</td>\n",
       "      <td>Customer917</td>\n",
       "      <td>cus_Q6F5nUeXK8doS8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>charge_automatically</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-05-13 17:24:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F0E48C3E-14472</td>\n",
       "      <td>2024-05-13 17:24:00+00:00</td>\n",
       "      <td>2024-05-13 17:24:00+00:00</td>\n",
       "      <td>2024-05-13 17:24:00+00:00</td>\n",
       "      <td>2024-05-23 17:24:00+00:00</td>\n",
       "      <td>2024-05-13 17:24:00+00:00</td>\n",
       "      <td>sub_1PG2bVCZ9aYYH5wiDYhOIisE</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18372</th>\n",
       "      <td>in_1PJfNQCZ9aYYH5wikrILiVWa</td>\n",
       "      <td>Customer917</td>\n",
       "      <td>cus_Q6F5nUeXK8doS8</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>True</td>\n",
       "      <td>charge_automatically</td>\n",
       "      <td>ch_3PJgK5CZ9aYYH5wi1BHnzZwq</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-05-23 17:24:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F0E48C3E-14784</td>\n",
       "      <td>2024-05-23 18:25:00+00:00</td>\n",
       "      <td>2024-05-23 18:25:00+00:00</td>\n",
       "      <td>2024-05-23 17:24:00+00:00</td>\n",
       "      <td>2025-05-23 17:24:00+00:00</td>\n",
       "      <td>2024-05-23 17:24:00+00:00</td>\n",
       "      <td>sub_1PG2bVCZ9aYYH5wiDYhOIisE</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12281</th>\n",
       "      <td>in_1QHoo0CZ9aYYH5wipsGTjQfU</td>\n",
       "      <td>Customer917</td>\n",
       "      <td>cus_Q6F5nUeXK8doS8</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>True</td>\n",
       "      <td>charge_automatically</td>\n",
       "      <td>ch_3QHoo2CZ9aYYH5wi1S3ibDFH</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-11-05 15:36:00+00:00</td>\n",
       "      <td>Customer Early Renew</td>\n",
       "      <td>F0E48C3E-20875</td>\n",
       "      <td>2024-11-05 15:36:00+00:00</td>\n",
       "      <td>2024-11-05 15:36:00+00:00</td>\n",
       "      <td>2024-11-05 15:36:00+00:00</td>\n",
       "      <td>2024-11-05 15:36:00+00:00</td>\n",
       "      <td>2025-05-23 17:24:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12280</th>\n",
       "      <td>in_1QHooTCZ9aYYH5wiIhWCKOAv</td>\n",
       "      <td>Customer917</td>\n",
       "      <td>cus_Q6F5nUeXK8doS8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>charge_automatically</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-11-05 15:37:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F0E48C3E-20876</td>\n",
       "      <td>2024-11-05 15:37:00+00:00</td>\n",
       "      <td>2024-11-05 15:37:00+00:00</td>\n",
       "      <td>2024-11-05 15:37:00+00:00</td>\n",
       "      <td>2025-11-05 15:37:00+00:00</td>\n",
       "      <td>2024-11-05 15:37:00+00:00</td>\n",
       "      <td>sub_1QHooTCZ9aYYH5wiIkZHzWV1</td>\n",
       "      <td>69</td>\n",
       "      <td>FVO3JKM7</td>\n",
       "      <td>paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>in_1RBI9ECZ9aYYH5wiPV6RcosO</td>\n",
       "      <td>Customer917</td>\n",
       "      <td>cus_Q6F5nUeXK8doS8</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>True</td>\n",
       "      <td>charge_automatically</td>\n",
       "      <td>ch_3RBI9HCZ9aYYH5wi16Ke2ngK</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-04-07 16:03:00+00:00</td>\n",
       "      <td>Customer Early Renew</td>\n",
       "      <td>F0E48C3E-31446</td>\n",
       "      <td>2025-04-07 16:03:00+00:00</td>\n",
       "      <td>2025-04-07 16:04:00+00:00</td>\n",
       "      <td>2025-04-07 16:03:00+00:00</td>\n",
       "      <td>2025-04-07 16:03:00+00:00</td>\n",
       "      <td>2025-11-05 15:37:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>in_1RBI9rCZ9aYYH5wiVehEQrMn</td>\n",
       "      <td>Customer917</td>\n",
       "      <td>cus_Q6F5nUeXK8doS8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>charge_automatically</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-04-07 16:04:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F0E48C3E-31447</td>\n",
       "      <td>2025-04-07 16:04:00+00:00</td>\n",
       "      <td>2025-04-07 16:04:00+00:00</td>\n",
       "      <td>2025-04-07 16:04:00+00:00</td>\n",
       "      <td>2026-04-07 16:04:00+00:00</td>\n",
       "      <td>2025-04-07 16:04:00+00:00</td>\n",
       "      <td>sub_1RBI9rCZ9aYYH5wiNlG3pArt</td>\n",
       "      <td>69</td>\n",
       "      <td>FVO3JKM7</td>\n",
       "      <td>paid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        invoice_id customer_name         customer_id  \\\n",
       "18684  in_1PG2bVCZ9aYYH5wi149OP50H   Customer917  cus_Q6F5nUeXK8doS8   \n",
       "18372  in_1PJfNQCZ9aYYH5wikrILiVWa   Customer917  cus_Q6F5nUeXK8doS8   \n",
       "12281  in_1QHoo0CZ9aYYH5wipsGTjQfU   Customer917  cus_Q6F5nUeXK8doS8   \n",
       "12280  in_1QHooTCZ9aYYH5wiIhWCKOAv   Customer917  cus_Q6F5nUeXK8doS8   \n",
       "1710   in_1RBI9ECZ9aYYH5wiPV6RcosO   Customer917  cus_Q6F5nUeXK8doS8   \n",
       "1709   in_1RBI9rCZ9aYYH5wiVehEQrMn   Customer917  cus_Q6F5nUeXK8doS8   \n",
       "\n",
       "       Amount Due  amount_paid  paid               Billing  \\\n",
       "18684         0.0          0.0  True  charge_automatically   \n",
       "18372        69.0         69.0  True  charge_automatically   \n",
       "12281        69.0         69.0  True  charge_automatically   \n",
       "12280         0.0          0.0  True  charge_automatically   \n",
       "1710         69.0         69.0  True  charge_automatically   \n",
       "1709          0.0          0.0  True  charge_automatically   \n",
       "\n",
       "                            Charge  Closed                  date_utc  \\\n",
       "18684                          NaN    True 2024-05-13 17:24:00+00:00   \n",
       "18372  ch_3PJgK5CZ9aYYH5wi1BHnzZwq    True 2024-05-23 17:24:00+00:00   \n",
       "12281  ch_3QHoo2CZ9aYYH5wi1S3ibDFH    True 2024-11-05 15:36:00+00:00   \n",
       "12280                          NaN    True 2024-11-05 15:37:00+00:00   \n",
       "1710   ch_3RBI9HCZ9aYYH5wi16Ke2ngK    True 2025-04-07 16:03:00+00:00   \n",
       "1709                           NaN    True 2025-04-07 16:04:00+00:00   \n",
       "\n",
       "                description          Number        Finalized At (UTC)  \\\n",
       "18684                   NaN  F0E48C3E-14472 2024-05-13 17:24:00+00:00   \n",
       "18372                   NaN  F0E48C3E-14784 2024-05-23 18:25:00+00:00   \n",
       "12281  Customer Early Renew  F0E48C3E-20875 2024-11-05 15:36:00+00:00   \n",
       "12280                   NaN  F0E48C3E-20876 2024-11-05 15:37:00+00:00   \n",
       "1710   Customer Early Renew  F0E48C3E-31446 2025-04-07 16:03:00+00:00   \n",
       "1709                    NaN  F0E48C3E-31447 2025-04-07 16:04:00+00:00   \n",
       "\n",
       "                    paid_at_utc Minimum Line Item Period Start (UTC)  \\\n",
       "18684 2024-05-13 17:24:00+00:00            2024-05-13 17:24:00+00:00   \n",
       "18372 2024-05-23 18:25:00+00:00            2024-05-23 17:24:00+00:00   \n",
       "12281 2024-11-05 15:36:00+00:00            2024-11-05 15:36:00+00:00   \n",
       "12280 2024-11-05 15:37:00+00:00            2024-11-05 15:37:00+00:00   \n",
       "1710  2025-04-07 16:04:00+00:00            2025-04-07 16:03:00+00:00   \n",
       "1709  2025-04-07 16:04:00+00:00            2025-04-07 16:04:00+00:00   \n",
       "\n",
       "      Maximum Line Item Period End (UTC)          Period End (UTC)  \\\n",
       "18684          2024-05-23 17:24:00+00:00 2024-05-13 17:24:00+00:00   \n",
       "18372          2025-05-23 17:24:00+00:00 2024-05-23 17:24:00+00:00   \n",
       "12281          2024-11-05 15:36:00+00:00 2025-05-23 17:24:00+00:00   \n",
       "12280          2025-11-05 15:37:00+00:00 2024-11-05 15:37:00+00:00   \n",
       "1710           2025-04-07 16:03:00+00:00 2025-11-05 15:37:00+00:00   \n",
       "1709           2026-04-07 16:04:00+00:00 2025-04-07 16:04:00+00:00   \n",
       "\n",
       "                    subscription_id  Total Discount Amount Applied Coupons  \\\n",
       "18684  sub_1PG2bVCZ9aYYH5wiDYhOIisE                      0             NaN   \n",
       "18372  sub_1PG2bVCZ9aYYH5wiDYhOIisE                      0             NaN   \n",
       "12281                           NaN                      0             NaN   \n",
       "12280  sub_1QHooTCZ9aYYH5wiIkZHzWV1                     69        FVO3JKM7   \n",
       "1710                            NaN                      0             NaN   \n",
       "1709   sub_1RBI9rCZ9aYYH5wiNlG3pArt                     69        FVO3JKM7   \n",
       "\n",
       "      inv_status  \n",
       "18684       paid  \n",
       "18372       paid  \n",
       "12281       paid  \n",
       "12280       paid  \n",
       "1710        paid  \n",
       "1709        paid  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_df['customer_id'].value_counts()\n",
    "inv_df[inv_df['customer_id'] == 'cus_Q6F5nUeXK8doS8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subscription_id</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>status</th>\n",
       "      <th>cancellation_reason</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>start_utc</th>\n",
       "      <th>current_period_start_utc</th>\n",
       "      <th>current_period_end_utc</th>\n",
       "      <th>trial_start_utc</th>\n",
       "      <th>trial_end_utc</th>\n",
       "      <th>canceled_at_utc</th>\n",
       "      <th>ended_at_utc</th>\n",
       "      <th>is_gifted_member</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10822</th>\n",
       "      <td>sub_1PG2bVCZ9aYYH5wiDYhOIisE</td>\n",
       "      <td>Customer917</td>\n",
       "      <td>cus_Q6F5nUeXK8doS8</td>\n",
       "      <td>canceled</td>\n",
       "      <td>cancellation_requested</td>\n",
       "      <td>2024-05-13 17:24:00+00:00</td>\n",
       "      <td>2024-05-13 17:24:00+00:00</td>\n",
       "      <td>2024-05-23 17:24:00+00:00</td>\n",
       "      <td>2025-05-23 17:24:00+00:00</td>\n",
       "      <td>2024-05-13 17:24:00+00:00</td>\n",
       "      <td>2024-05-23 17:24:00+00:00</td>\n",
       "      <td>2024-11-05 15:37:00+00:00</td>\n",
       "      <td>2024-11-05 15:37:00+00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6672</th>\n",
       "      <td>sub_1QHooTCZ9aYYH5wiIkZHzWV1</td>\n",
       "      <td>Customer917</td>\n",
       "      <td>cus_Q6F5nUeXK8doS8</td>\n",
       "      <td>canceled</td>\n",
       "      <td>cancellation_requested</td>\n",
       "      <td>2024-11-05 15:37:00+00:00</td>\n",
       "      <td>2024-11-05 15:37:00+00:00</td>\n",
       "      <td>2024-11-05 15:37:00+00:00</td>\n",
       "      <td>2025-11-05 15:37:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2025-04-07 16:04:00+00:00</td>\n",
       "      <td>2025-04-07 16:04:00+00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>sub_1RBI9rCZ9aYYH5wiNlG3pArt</td>\n",
       "      <td>Customer917</td>\n",
       "      <td>cus_Q6F5nUeXK8doS8</td>\n",
       "      <td>active</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-04-07 16:04:00+00:00</td>\n",
       "      <td>2025-04-07 16:04:00+00:00</td>\n",
       "      <td>2025-04-07 16:04:00+00:00</td>\n",
       "      <td>2026-04-07 16:04:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    subscription_id customer_name         customer_id  \\\n",
       "10822  sub_1PG2bVCZ9aYYH5wiDYhOIisE   Customer917  cus_Q6F5nUeXK8doS8   \n",
       "6672   sub_1QHooTCZ9aYYH5wiIkZHzWV1   Customer917  cus_Q6F5nUeXK8doS8   \n",
       "971    sub_1RBI9rCZ9aYYH5wiNlG3pArt   Customer917  cus_Q6F5nUeXK8doS8   \n",
       "\n",
       "         status     cancellation_reason               created_utc  \\\n",
       "10822  canceled  cancellation_requested 2024-05-13 17:24:00+00:00   \n",
       "6672   canceled  cancellation_requested 2024-11-05 15:37:00+00:00   \n",
       "971      active                     NaN 2025-04-07 16:04:00+00:00   \n",
       "\n",
       "                      start_utc  current_period_start_utc  \\\n",
       "10822 2024-05-13 17:24:00+00:00 2024-05-23 17:24:00+00:00   \n",
       "6672  2024-11-05 15:37:00+00:00 2024-11-05 15:37:00+00:00   \n",
       "971   2025-04-07 16:04:00+00:00 2025-04-07 16:04:00+00:00   \n",
       "\n",
       "         current_period_end_utc           trial_start_utc  \\\n",
       "10822 2025-05-23 17:24:00+00:00 2024-05-13 17:24:00+00:00   \n",
       "6672  2025-11-05 15:37:00+00:00                       NaT   \n",
       "971   2026-04-07 16:04:00+00:00                       NaT   \n",
       "\n",
       "                  trial_end_utc           canceled_at_utc  \\\n",
       "10822 2024-05-23 17:24:00+00:00 2024-11-05 15:37:00+00:00   \n",
       "6672                        NaT 2025-04-07 16:04:00+00:00   \n",
       "971                         NaT                       NaT   \n",
       "\n",
       "                   ended_at_utc  is_gifted_member  \n",
       "10822 2024-11-05 15:37:00+00:00             False  \n",
       "6672  2025-04-07 16:04:00+00:00             False  \n",
       "971                         NaT             False  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df[sub_df['customer_id'] == 'cus_Q6F5nUeXK8doS8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge inv_df and sub_df on 'subscription_id'\n",
    "merged_df = inv_df.merge(sub_df, on='subscription_id', suffixes=('_inv', '_sub'), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_id_inv\n",
      "cus_OhZs6NtQ3RSc9j    1\n",
      "cus_OhZsIHcfYXqNJx    1\n",
      "cus_OhZtIUk5q419NR    1\n",
      "cus_Oha922cf4488T3    1\n",
      "cus_OhaH3sQTOqvuAH    1\n",
      "                     ..\n",
      "cus_SMYvL9t7buzWC9    1\n",
      "cus_SMaCh3diB5702c    1\n",
      "cus_SMab6nDMynXbYk    1\n",
      "cus_SMas6YsqkS3FUn    1\n",
      "cus_SMb0NMrlhzvojr    1\n",
      "Name: invoice_id, Length: 21491, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Group by 'customer_id' and display the count of invoices per customer\n",
    "invoice_counts = merged_df.groupby('customer_id_inv')['invoice_id'].count()\n",
    "print(invoice_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id_inv\n",
       "cus_OhaWkzl9u5973o    3\n",
       "cus_OhagJTEOs7LZLk    3\n",
       "cus_OhaiLVc3wUwNWu    3\n",
       "cus_OhartoZLR9vWnB    4\n",
       "cus_Ohc4lazRKnDFZ3    3\n",
       "                     ..\n",
       "cus_Rd1v42e9nVT48M    4\n",
       "cus_RdqL5EFDuF6gmh    4\n",
       "cus_RdqV2AefC7WNOW    3\n",
       "cus_Rg4og8ntkWmlXA    4\n",
       "cus_Rh44ejQ8OJ7bDi    4\n",
       "Name: invoice_id, Length: 2524, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
