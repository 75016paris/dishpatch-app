{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 11, 'axes.labelsize': 10, 'axes.titlesize': 16})\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['axes.edgecolor'] = 'black'\n",
    "#plt.rcParams['xtick.color'] = 'black'\n",
    "plt.rcParams['xtick.color'] = 'white'\n",
    "#plt.rcParams['ytick.color'] = 'black'\n",
    "plt.rcParams['ytick.color'] = 'white'\n",
    "plt.rcParams['figure.figsize'] = (22, 11)\n",
    "\n",
    "# Grid with opacity and in background\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.color'] = 'lightgray'\n",
    "plt.rcParams['grid.alpha'] = 0.5\n",
    "plt.rcParams['axes.axisbelow'] = True\n",
    "\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "#plt.rcParams['axes.titlecolor'] = 'black'\n",
    "plt.rcParams['axes.titlecolor'] = 'white'\n",
    "#plt.rcParams['axes.labelcolor'] = 'black'\n",
    "plt.rcParams['legend.labelcolor'] = 'black'\n",
    "plt.rcParams['legend.facecolor'] = 'white'\n",
    "plt.rcParams['legend.edgecolor'] = 'gray'\n",
    "plt.rcParams['text.color'] = 'black'\n",
    "sns.set_palette(\"viridis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set TODAY DATE\n",
    "# today_date = pd.Timestamp.now(tz='UTC')\n",
    "today_date = pd.Timestamp('2025-05-30', tz='UTC')  # For testing purposes\n",
    "\n",
    "\n",
    "# Set REFUND PERDIOD DURATION\n",
    "REFUND_PERIOD_DAYS = 14  # Duration of the refund period in days\n",
    "\n",
    "# Set thresholds for cleaning\n",
    "HIGH_VOLUME_THRESHOLD = 5\n",
    "DUPLICATE_THRESHOLD_MINUTES = 15\n",
    "\n",
    "\n",
    "# Set DIRECTORIES\n",
    "data_dir = 'both_csv_go_here'\n",
    "archive_csv_dir = 'archive/csv'\n",
    "archive_png_dir = 'archive/analysis/png'\n",
    "archive_pdf_dir = 'archive/analysis/pdf'\n",
    "analysis_dir = 'analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ ARCHIVING SUMMARY (2025-06-27 09:52:45):\n",
      "   PNG files transferred: 0\n",
      "   PDF files transferred: 0\n",
      "   Total files archived: 0\n",
      "üóëÔ∏è  No files to clean in analysis directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_file_creation_date(file_path):\n",
    "    \"\"\"\n",
    "    Get the creation date of a file and return it as a formatted string\n",
    "    Returns format: YYYY-MM-DD\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get file creation time (or modification time if creation not available)\n",
    "        if os.name == 'nt':  # Windows\n",
    "            creation_time = os.path.getctime(file_path)\n",
    "        else:  # Unix/Linux/Mac\n",
    "            creation_time = os.path.getmtime(file_path)\n",
    "\n",
    "        # Convert to datetime and format\n",
    "        creation_date = datetime.fromtimestamp(creation_time)\n",
    "        return creation_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error getting creation date for {file_path}: {e}\")\n",
    "        # Fallback to today's date\n",
    "        return datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "def transfer_files_to_archive():\n",
    "    \"\"\"\n",
    "    Enhanced version with date-based organization\n",
    "    Transfer PNG files from analysis_dir to archive_png_dir/YYYY-MM-DD/\n",
    "    Transfer PDF files from analysis_dir to archive_pdf_dir/YYYY-MM-DD/\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # === TRANSFER PNG FILES ===\n",
    "    png_files = glob.glob(os.path.join(analysis_dir, \"*.png\"))\n",
    "    png_transferred = 0\n",
    "\n",
    "    for png_file in png_files:\n",
    "        filename = os.path.basename(png_file)\n",
    "\n",
    "        # Get creation date for organization\n",
    "        creation_date = get_file_creation_date(png_file)\n",
    "\n",
    "        # Create date-based directory in archive\n",
    "        date_archive_dir = os.path.join(archive_png_dir, creation_date)\n",
    "        os.makedirs(date_archive_dir, exist_ok=True)\n",
    "\n",
    "        # Set destination with date organization\n",
    "        destination = os.path.join(date_archive_dir, filename)\n",
    "\n",
    "        try:\n",
    "            # Copy file to archive (keep original in analysis_dir)\n",
    "            shutil.copy2(png_file, destination)\n",
    "            print(f\"üìä PNG archived: {creation_date}/{filename}\")\n",
    "            png_transferred += 1\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error archiving PNG {filename}: {e}\")\n",
    "\n",
    "    # === TRANSFER PDF FILES ===\n",
    "    pdf_files = glob.glob(os.path.join(analysis_dir, \"*.pdf\"))\n",
    "    pdf_transferred = 0\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        filename = os.path.basename(pdf_file)\n",
    "\n",
    "        # Get creation date for organization\n",
    "        creation_date = get_file_creation_date(pdf_file)\n",
    "\n",
    "        # Create date-based directory in archive\n",
    "        date_archive_dir = os.path.join(archive_pdf_dir, creation_date)\n",
    "        os.makedirs(date_archive_dir, exist_ok=True)\n",
    "\n",
    "        # Set destination with date organization\n",
    "        destination = os.path.join(date_archive_dir, filename)\n",
    "\n",
    "        try:\n",
    "            # Copy file to archive (keep original in analysis_dir)\n",
    "            shutil.copy2(pdf_file, destination)\n",
    "            print(f\"üìÑ PDF archived: {creation_date}/{filename}\")\n",
    "            pdf_transferred += 1\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error archiving PDF {filename}: {e}\")\n",
    "\n",
    "    # === SUMMARY ===\n",
    "    print(f\"\\nüì¶ ARCHIVING SUMMARY ({timestamp}):\")\n",
    "    print(f\"   PNG files transferred: {png_transferred}\")\n",
    "    print(f\"   PDF files transferred: {pdf_transferred}\")\n",
    "    print(f\"   Total files archived: {png_transferred + pdf_transferred}\")\n",
    "\n",
    "    return png_transferred, pdf_transferred\n",
    "\n",
    "\n",
    "def clean_analysis_dir_after_archive():\n",
    "    \"\"\"\n",
    "    OPTIONAL: Remove files from analysis_dir after successful archiving\n",
    "    USE WITH CAUTION - This will delete the original files!\n",
    "    Enhanced with better logging and date information\n",
    "    \"\"\"\n",
    "    # Get all PNG and PDF files in analysis_dir\n",
    "    png_files = glob.glob(os.path.join(analysis_dir, \"*.png\"))\n",
    "    pdf_files = glob.glob(os.path.join(analysis_dir, \"*.pdf\"))\n",
    "    all_files = png_files + pdf_files\n",
    "\n",
    "    if not all_files:\n",
    "        print(\"üóëÔ∏è  No files to clean in analysis directory\")\n",
    "        return 0\n",
    "\n",
    "    print(f\"üóëÔ∏è  Cleaning {len(all_files)} files from {analysis_dir}...\")\n",
    "\n",
    "    cleaned_files = 0\n",
    "\n",
    "    for file_path in all_files:\n",
    "        try:\n",
    "            filename = os.path.basename(file_path)\n",
    "            creation_date = get_file_creation_date(file_path)\n",
    "\n",
    "            os.remove(file_path)\n",
    "            print(f\"üóëÔ∏è  Cleaned: {filename} (was from {creation_date})\")\n",
    "            cleaned_files += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error cleaning {file_path}: {e}\")\n",
    "\n",
    "    print(f\"üßπ Cleanup complete: {cleaned_files} files removed from {analysis_dir}\")\n",
    "    return cleaned_files\n",
    "\n",
    "\n",
    "transfer_files_to_archive()\n",
    "clean_analysis_dir_after_archive()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  File 1:\n",
      " DishpatchSubscriptionData_NIklas_Sanitised - subscriptions.csv\n",
      "  File 2:\n",
      " DishpatchInvoiceData_NIklas_Sanitised - invoices.csv\n",
      "\n",
      "Loading CSV files:\n",
      "  File 1: DishpatchSubscriptionData_NIklas_Sanitised - subscriptions.csv\n",
      "  File 2: DishpatchInvoiceData_NIklas_Sanitised - invoices.csv\n",
      "\n",
      "Successfully loaded:\n",
      "  sub_raw: 20443 rows, 34 columns\n",
      "  inv_raw: 33239 rows, 53 columns\n",
      "\n",
      "DataFrames available as: sub_raw, inv_raw\n",
      "\n",
      "Processing complete!\n",
      "***************************************************\n"
     ]
    }
   ],
   "source": [
    "# LOADING CSV\n",
    "\n",
    "# Toggle this flag to True in production\n",
    "RENAME_FILES = False\n",
    "MOVE_FILES = False\n",
    "\n",
    "# Ensure archive directory exists\n",
    "os.makedirs(archive_csv_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# List and sort files by creation time\n",
    "files = [\n",
    "    os.path.join(data_dir, f)\n",
    "    for f in os.listdir(data_dir)\n",
    "    if os.path.isfile(os.path.join(data_dir, f)) and f.endswith('.csv')]\n",
    "sorted_files = sorted(files, key=os.path.getctime, reverse=True)\n",
    "\n",
    "# Check if we have exactly 2 CSV files\n",
    "if len(sorted_files) != 2:\n",
    "    print(f\"Error: Expected 2 CSV files, found {len(sorted_files)}\")\n",
    "    print(\"Files found:\", [os.path.basename(f) for f in sorted_files])\n",
    "    exit(1)\n",
    "\n",
    "for i, file_path in enumerate(sorted_files, 1):\n",
    "    print(f\"  File {i}:\\n {os.path.basename(file_path)}\")\n",
    "\n",
    "# Loop over files\n",
    "processed_files = []\n",
    "for file_path in sorted_files:\n",
    "    created_at = datetime.fromtimestamp(os.path.getctime(file_path))\n",
    "    timestamp_str = created_at.strftime('%Y-%m-%d_%H-%M')\n",
    "    original_name = os.path.basename(file_path)\n",
    "    new_name = f\"{timestamp_str}_{original_name}\"\n",
    "\n",
    "    if RENAME_FILES:\n",
    "        if not original_name.startswith(timestamp_str):\n",
    "            new_path = os.path.join(data_dir, new_name)\n",
    "            os.rename(file_path, new_path)\n",
    "            print(f\"Renamed:\\n {original_name} ‚Üí\\n {new_name}\\n\")\n",
    "            processed_files.append(new_path)\n",
    "        else:\n",
    "            processed_files.append(file_path)\n",
    "    else:\n",
    "        processed_files.append(file_path)\n",
    "\n",
    "# Load both CSV files into pandas DataFrames\n",
    "file1_path, file2_path = processed_files[0], processed_files[1]\n",
    "print(f\"\\nLoading CSV files:\")\n",
    "print(f\"  File 1: {os.path.basename(file1_path)}\")\n",
    "print(f\"  File 2: {os.path.basename(file2_path)}\")\n",
    "\n",
    "try:\n",
    "    sub_raw = pd.read_csv(file1_path, low_memory=False)\n",
    "    inv_raw = pd.read_csv(file2_path, low_memory=False)\n",
    "    print(f\"\\nSuccessfully loaded:\")\n",
    "    print(f\"  sub_raw: {sub_raw.shape[0]} rows, {sub_raw.shape[1]} columns\")\n",
    "    print(f\"  inv_raw: {inv_raw.shape[0]} rows, {inv_raw.shape[1]} columns\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV files: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Move files to archive\n",
    "if MOVE_FILES:\n",
    "    for file_path in processed_files:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        archive_path = os.path.join(archive_csv_dir, file_name)\n",
    "\n",
    "        if not os.path.exists(archive_path):\n",
    "            os.rename(file_path, archive_path)\n",
    "            print(f\"Moved: {file_name} to archive\")\n",
    "        else:\n",
    "            print(f\"Already archived: {file_name}\")\n",
    "else:\n",
    "    for file_path in processed_files:\n",
    "        file_name = os.path.basename(file_path)\n",
    "\n",
    "print(\"\\nDataFrames available as: sub_raw, inv_raw\")\n",
    "print(\"\\nProcessing complete!\")\n",
    "print('***************************************************')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Reference date (TODAY) : 30-05-2025\n",
      "20443 entries loaded from both_csv_go_here/DishpatchInvoiceData_NIklas_Sanitised - invoices.csv\n",
      "***************************************************\n"
     ]
    }
   ],
   "source": [
    "# DATA PREPROCESSING (customer_df)\n",
    "def preprocess_data(input_df):\n",
    "    \"\"\"Clean and preprocess the subscription data\"\"\"\n",
    "    df = input_df.copy()\n",
    "\n",
    "    # Date conversion\n",
    "    date_cols = [col for col in df.columns if '(UTC)' in col]\n",
    "    for col in date_cols:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce', utc=True)\n",
    "\n",
    "    df = df.sort_values(by='Created (UTC)')\n",
    "\n",
    "    # Column selection and renaming\n",
    "    columns_to_keep = [\n",
    "        'id', 'Customer Name', 'Customer ID', 'Status', 'Cancellation Reason',\n",
    "        'Created (UTC)', 'Start (UTC)', 'Current Period Start (UTC)',\n",
    "        'Current Period End (UTC)', 'Trial Start (UTC)', 'Trial End (UTC)',\n",
    "        'Canceled At (UTC)', 'Ended At (UTC)', 'senderShopifyCustomerId (metadata)'\n",
    "    ]\n",
    "\n",
    "    df = df[columns_to_keep]\n",
    "\n",
    "    df.rename(columns={\n",
    "        'id': 'subscription_id',\n",
    "        'Customer ID': 'customer_id',\n",
    "        'Customer Name': 'customer_name',\n",
    "        'Status': 'status',\n",
    "        'Cancellation Reason': 'cancellation_reason',\n",
    "        'Created (UTC)': 'created_utc',\n",
    "        'Start (UTC)': 'start_utc',\n",
    "        'Current Period Start (UTC)': 'current_period_start_utc',\n",
    "        'Current Period End (UTC)': 'current_period_end_utc',\n",
    "        'Trial Start (UTC)': 'trial_start_utc',\n",
    "        'Trial End (UTC)': 'trial_end_utc',\n",
    "        'Canceled At (UTC)': 'canceled_at_utc',\n",
    "        'Ended At (UTC)': 'ended_at_utc',\n",
    "        'senderShopifyCustomerId (metadata)': 'is_gifted_member'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Convert is_gifted_member to boolean\n",
    "    df['is_gifted_member'] = df['is_gifted_member'].notna()\n",
    "\n",
    "\n",
    "    # Reference date for analysis\n",
    "    print(f\"üìÖ Reference date (TODAY) : {today_date.strftime('%d-%m-%Y')}\")\n",
    "    print(f\"{len(df)} entries loaded from {file_path}\")\n",
    "    print('***************************************************')\n",
    "\n",
    "    return df\n",
    "\n",
    "sub_df = preprocess_data(sub_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 377 customers with multiple subscriptions.\n",
      "Total single_sub_df: 19599, with 19599 unique customers\n",
      "Total multi_sub_df: 844, with 377 unique customers\n"
     ]
    }
   ],
   "source": [
    "# REMOVE ALL MULTI-SUB customer_id from sub_df, put them im a new df multisub_df\n",
    "def remove_multi_subscriptions(df):\n",
    "    \"\"\"Remove customers with multiple subscriptions and return a new DataFrame\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Count subscriptions per customer\n",
    "    subscription_counts = df['customer_id'].value_counts()\n",
    "\n",
    "    # Get customers with more than one subscription\n",
    "    multi_sub_customers = subscription_counts[subscription_counts > 1].index.tolist()\n",
    "\n",
    "    # Filter out these customers from the main DataFrame\n",
    "    single_sub_df = df[~df['customer_id'].isin(multi_sub_customers)]\n",
    "\n",
    "    # Create a new DataFrame for multi-subscription customers\n",
    "    multi_sub_df = df[df['customer_id'].isin(multi_sub_customers)]\n",
    "\n",
    "    print(f\"Removed {len(multi_sub_customers)} customers with multiple subscriptions.\")\n",
    "    print(f\"Total single_sub_df: {len(single_sub_df)}, with {len(single_sub_df['customer_id'].unique())} unique customers\")\n",
    "    print(f\"Total multi_sub_df: {len(multi_sub_df)}, with {len(multi_sub_df['customer_id'].unique())} unique customers\")\n",
    "\n",
    "\n",
    "    return single_sub_df, multi_sub_df\n",
    "\n",
    "\n",
    "sub_df, multisub_df = remove_multi_subscriptions(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPROCESSING (invoices df)\n",
    "def preprocess_data_invoice(input_df):\n",
    "    \"\"\"Clean and preprocess the subscription data\"\"\"\n",
    "    df = input_df.copy()\n",
    "\n",
    "    # Date conversion\n",
    "    date_cols = [col for col in df.columns if '(UTC)' in col]\n",
    "    for col in date_cols:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce', utc=True)\n",
    "\n",
    "\n",
    "    # Column selection and renaming\n",
    "    columns_to_keep = [\n",
    "        'id', 'Customer Name', 'Customer', 'Amount Due', 'Amount Paid', 'Paid', 'Billing', 'Charge', 'Closed',\n",
    "        'Date (UTC)', 'Description', 'Number', 'Finalized At (UTC)',\n",
    "        'Paid At (UTC)', 'Minimum Line Item Period Start (UTC)', 'Maximum Line Item Period End (UTC)',\n",
    "        'Period End (UTC)', 'Subscription', 'Total Discount Amount', 'Applied Coupons', 'Status'\n",
    "        ]\n",
    "\n",
    "    df = df[columns_to_keep]\n",
    "\n",
    "    df.rename(columns={\n",
    "        'id': 'invoice_id',\n",
    "        'Status': 'inv_status',\n",
    "        'Customer': 'customer_id',\n",
    "        'Customer Name': 'customer_name',\n",
    "        'Date (UTC)' : 'date_utc',\n",
    "        'Description': 'description',\n",
    "        'Paid At (UTC)': 'paid_at_utc',\n",
    "        'Amount Paid': 'amount_paid',\n",
    "        'Subscription': 'subscription_id',\n",
    "    }, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "inv_df = preprocess_data_invoice(inv_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGING DATAFRAMES\n",
    "def merge_dataframes(sub_df, inv_df):\n",
    "    \"\"\"Merge two DataFrames on 'subscription_id' and 'customer_id'\"\"\"\n",
    "    # Ensure both DataFrames have the same columns for merging\n",
    "\n",
    "    merged_df = pd.merge(sub_df, inv_df, on=['subscription_id'], how='outer')\n",
    "\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "#df = merge_dataframes(sub_df, inv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 subscriptions removed from 0 customers with more than 5 subscriptions\n",
      "***************************************************\n"
     ]
    }
   ],
   "source": [
    "# Removing customers with more than 5 subscriptions (Probably testing accounts)\n",
    "def remove_high_volume_customers(df, threshold=HIGH_VOLUME_THRESHOLD):\n",
    "    \"\"\"Remove customers with more than a specified number of subscriptions\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    original_count = len(df)\n",
    "\n",
    "    customer_counts = df['customer_id'].value_counts()\n",
    "    high_volume_customers = customer_counts[customer_counts > threshold].index\n",
    "\n",
    "    df = df[~df['customer_id'].isin(high_volume_customers)]\n",
    "\n",
    "    print(f'{original_count - len(df)} subscriptions removed from \\\n",
    "{len(high_volume_customers)} customers with more than {threshold} subscriptions')\n",
    "    print('***************************************************')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "sub_df = remove_high_volume_customers(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CANCEL DURING TRIAL PERIOD\n",
    "def cancel_during_trial(df):\n",
    "    \"\"\"Check if a member canceled during their trial period\"\"\"\n",
    "    df =df.copy()\n",
    "\n",
    "    df['canceled_during_trial'] = (\n",
    "        (df['canceled_at_utc'].notna()) &\n",
    "        (df['trial_end_utc'] > df['canceled_at_utc'])\n",
    "    )\n",
    "    return df\n",
    "\n",
    "sub_df = cancel_during_trial(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD  SETTING REFUND PERIOD END UTC\n",
    "def refund_period_end_utc(df, REFUND_PERIOD_DAYS):\n",
    "    df = df.copy()\n",
    "    df['refund_period_end_utc'] = np.where(\n",
    "        (df['trial_end_utc'].notna()) & (df['trial_end_utc'] > df['current_period_start_utc']),\n",
    "        df['trial_end_utc'] + pd.Timedelta(days=REFUND_PERIOD_DAYS),\n",
    "        df['current_period_start_utc'] + pd.Timedelta(days=REFUND_PERIOD_DAYS)\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "sub_df = refund_period_end_utc(sub_df, REFUND_PERIOD_DAYS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REFUND PERIOD END TIME\n",
    "# This function sets the 'refund_period_end_utc' column for each subscription.\n",
    "# The refund period end date is calculated differently depending on whether the subscription started with a trial:\n",
    "# - If 'trial_start_utc' is not null (i.e., the subscription had a trial), the refund period ends REFUND_PERIOD_DAYS after the trial ends ('trial_end_utc').\n",
    "# - If there was no trial ('trial_start_utc' is null), the refund period ends REFUND_PERIOD_DAYS after the current paid period starts ('current_period_start_utc').\n",
    "def refund_period_end_utc(df, REFUND_PERIOD_DAYS):\n",
    "    df = df.copy()\n",
    "    df['refund_period_end_utc'] = np.where(\n",
    "        df['trial_start_utc'].notna() &\n",
    "        (df['trial_end_utc'] > df['current_period_start_utc']),\n",
    "        df['trial_end_utc'] + pd.Timedelta(days=REFUND_PERIOD_DAYS),\n",
    "        df['current_period_start_utc'] + pd.Timedelta(days=REFUND_PERIOD_DAYS)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Apply the function to the subscriptions DataFrame\n",
    "sub_df = refund_period_end_utc(sub_df, REFUND_PERIOD_DAYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CANCEL DURRING REFUND PERIOD\n",
    "def canceled_during_refund_period(df):\n",
    "    \"\"\"Check if a member canceled during their refund period\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    df['canceled_during_refund_period'] = (\n",
    "        (df['canceled_at_utc'].notna()) &\n",
    "        (df['canceled_during_trial'] == False) &\n",
    "        (df['refund_period_end_utc'] > df['canceled_at_utc'])\n",
    "    )\n",
    "    return df\n",
    "\n",
    "sub_df = canceled_during_refund_period(sub_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL MEMBER STATUS\n",
    "def full_member_status(df):\n",
    "    \"\"\"Determine if a customer is a full member based on business logic\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Full member if:\n",
    "    # 1. Not canceled during trial\n",
    "    # 2. Not canceled during refund period\n",
    "    # 3. Not gifted\n",
    "    # 4. Trial ended more than 14 days ago (if no trial, current_period_start_utc > 14 days ago)\n",
    "\n",
    "    no_early_cancellation = (\n",
    "        (~df['canceled_during_trial']) &\n",
    "        (~df['canceled_during_refund_period'])\n",
    "    )\n",
    "\n",
    "    not_gifted = (~df['is_gifted_member'])\n",
    "\n",
    "    refund_period_passed = (\n",
    "            (today_date > df['refund_period_end_utc'])\n",
    "            )\n",
    "\n",
    "    df['is_full_member'] = (\n",
    "        no_early_cancellation &\n",
    "        not_gifted &\n",
    "        refund_period_passed\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "sub_df = full_member_status(sub_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAYING MEMBERS\n",
    "def paying_members(df):\n",
    "    \"\"\"Determine if a customer is a paying member\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Paying member if:\n",
    "    # 1. Not canceled\n",
    "    # 2. Not gifted\n",
    "\n",
    "    no_early_cancellation = (\n",
    "        (~df['canceled_during_trial']) &\n",
    "        (~df['canceled_during_refund_period'])\n",
    "    )\n",
    "\n",
    "    not_gifted = (~df['is_gifted_member'])\n",
    "\n",
    "\n",
    "    df['is_paying_member'] = (\n",
    "        no_early_cancellation &\n",
    "        not_gifted\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "sub_df = paying_members(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ended_at_utc when needed\n",
    "def add_ended_at_utc(df, today_date):\n",
    "    \"\"\"add ended_at_utc when needed\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # if canceled during trial, set ended_at_utc to trial_end_utc\n",
    "    df['ended_at_utc'] = np.where(\n",
    "        (df['ended_at_utc'].isna()) & (df['canceled_during_trial']),\n",
    "        df['trial_end_utc'],\n",
    "        df['ended_at_utc']\n",
    "    )\n",
    "\n",
    "    # if canceled during refund period, set ended_at_utc to canceled_at_utc\n",
    "    df['ended_at_utc'] = np.where(\n",
    "        (df['ended_at_utc'].isna()) &\n",
    "        (df['canceled_during_refund_period']) &\n",
    "        (~df['canceled_during_trial']),\n",
    "        df['canceled_at_utc'],\n",
    "        df['ended_at_utc']\n",
    "    )\n",
    "\n",
    "    # if canceled after refund period, set ended_at_utc to current_period_end_utc\n",
    "    df['ended_at_utc'] = np.where(\n",
    "        (df['ended_at_utc'].isna()) &\n",
    "        (df['canceled_at_utc'].notna()) &\n",
    "        (~df['canceled_during_refund_period']) &\n",
    "        (~df['canceled_during_trial']),\n",
    "        np.minimum(df['current_period_end_utc'], today_date),\n",
    "        df['ended_at_utc']\n",
    "    )\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "sub_df = add_ended_at_utc(sub_df, today_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATING DURATIONS\n",
    "def calculate_duration(df, today_date):  # ‚Üê AJOUTER today_date en param√®tre\n",
    "    \"\"\"Calculate various durations in days with proper business logic\"\"\"\n",
    "\n",
    "    # Trial duration (if trial exists)\n",
    "    df['trial_duration_planned'] = (df['trial_end_utc'] - df['trial_start_utc']).dt.days.fillna(0)\n",
    "\n",
    "    # Pour les annulations pendant trial, limiter trial_duration √† la vraie utilisation\n",
    "    df['trial_duration'] = np.where(\n",
    "        df['ended_at_utc'] < df['trial_end_utc'],  # Annul√© pendant trial\n",
    "        np.maximum(0, (df['ended_at_utc'] - df['trial_start_utc']).dt.days),  # Dur√©e r√©elle\n",
    "        df['trial_duration_planned']  # Sinon dur√©e pr√©vue\n",
    "    )\n",
    "\n",
    "    # Current period duration\n",
    "    df['current_period_duration'] = (df['current_period_end_utc'] - df['current_period_start_utc']).dt.days\n",
    "\n",
    "    # Trial-only subscription\n",
    "    df['trial_only_subscription'] = (\n",
    "        df['trial_start_utc'].notna() &\n",
    "        df['trial_end_utc'].notna() &\n",
    "        (df['trial_duration'] == df['current_period_duration'])\n",
    "    )\n",
    "\n",
    "    # Gift duration (only for gifted members)\n",
    "    df['gift_duration'] = df['current_period_duration'].where(df['is_gifted_member'], 0)\n",
    "\n",
    "    # Days until end for active subscriptions\n",
    "    df['end_in'] = ((df['current_period_end_utc'] - today_date).dt.days).where(df['status'] == 'active', np.nan)\n",
    "\n",
    "    # ‚Üê MODIFICATION ICI : Limiter real_duration √† la dur√©e max possible\n",
    "    df['real_duration'] = np.where(\n",
    "        df['ended_at_utc'].notna() & (df['status'] != 'trialing'),\n",
    "        (df['ended_at_utc'] - df['created_utc']).dt.days,\n",
    "        (today_date - df['created_utc']).dt.days\n",
    "    )\n",
    "\n",
    "    # ‚Üê AJOUTER CETTE VALIDATION\n",
    "    max_possible = (today_date - df['created_utc'].min()).days\n",
    "    df['real_duration'] = np.minimum(df['real_duration'], max_possible)\n",
    "\n",
    "    df['paid_duration'] = df['real_duration'] - df['trial_duration']\n",
    "\n",
    "    return df\n",
    "\n",
    "# ‚Üê MODIFICATION DE L'APPEL\n",
    "sub_df = calculate_duration(sub_df, today_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEEKS ARE FROM MONDAY TO SUNDAY\n",
    "def get_specific_past_week(weeks_back=1, reference_date=None):\n",
    "    \"\"\"\n",
    "    Get specific date for a specific week.\n",
    "    weeks_back=1 : last week (from Monday to Sunday)\n",
    "    weeks_back=2 : previous week (from Monday to Sunday)\n",
    "    weeks_back=3 : three weeks ago (from Monday to Sunday)\n",
    "    \"\"\"\n",
    "\n",
    "    if reference_date is None:\n",
    "        today = pd.Timestamp.now(tz='UTC')\n",
    "    else:\n",
    "        if hasattr(reference_date, 'tz') and reference_date.tz is not None:\n",
    "            today = pd.to_datetime(reference_date).tz_convert('UTC')\n",
    "        else:\n",
    "            today = pd.to_datetime(reference_date).tz_localize('UTC')\n",
    "\n",
    "\n",
    "    # Finding the Monday of the target week\n",
    "    days_since_monday = today.weekday()\n",
    "    this_monday = today - pd.Timedelta(days=days_since_monday)\n",
    "    target_monday = this_monday - pd.Timedelta(days=7 * weeks_back)\n",
    "    target_sunday = target_monday + pd.Timedelta(days=6)\n",
    "\n",
    "    week_start = target_monday.normalize()  # 00:00:00\n",
    "    week_end = target_sunday.normalize() + pd.Timedelta(hours=23, minutes=59, seconds=59)  # 23:59:59\n",
    "\n",
    "    monday = target_monday.strftime('%d-%m-%y')\n",
    "    sunday = target_sunday.strftime('%d-%m-%y')\n",
    "\n",
    "    # Las week info\n",
    "    week_info = {\n",
    "        'weeks_ago': weeks_back,\n",
    "        'week_start': week_start,\n",
    "        'week_end': week_end,\n",
    "        'year': target_monday.year,\n",
    "        'week_number': target_monday.isocalendar().week,\n",
    "        'year_week': f\"{target_monday.year}-W{target_monday.isocalendar().week:02d}\",\n",
    "        'monday': monday,\n",
    "        'sunday': sunday,\n",
    "    }\n",
    "\n",
    "    return week_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Active full member: 5416\n",
      "Total not active full member: 1632\n"
     ]
    }
   ],
   "source": [
    "def get_full_members_count(df):\n",
    "    \"\"\"Count the number of full members\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    df = df[df['is_full_member'] == True]\n",
    "    df_active = df[df['status'] == 'active']\n",
    "    df_not_active = df[df['status'] != 'active']\n",
    "\n",
    "    active = len(df_active)\n",
    "    print(f\"Total Active full member: {active}\")\n",
    "    print(f\"Total not active full member: {len(df_not_active)}\")\n",
    "\n",
    "    dict_full_members = {'active': active,\n",
    "                         'not_active': len(df_not_active)\n",
    "                         }\n",
    "\n",
    "    return dict_full_members\n",
    "\n",
    "\n",
    "dict_full_member = get_full_members_count(sub_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New trials last week (2025-W21): 70\n",
      "New trials last week (2025-W20): 110\n"
     ]
    }
   ],
   "source": [
    "# how many trial this week\n",
    "def get_new_trial_last_week(df, weeks_back=1):\n",
    "    \"\"\"Count new trials started this week\"\"\"\n",
    "    week_info = get_specific_past_week(weeks_back=weeks_back, reference_date=today_date)\n",
    "\n",
    "    # Filter for the current week\n",
    "    df_week = df[(df['trial_start_utc'] >= week_info['week_start']) &\n",
    "                 (df['trial_start_utc'] < week_info['week_end'])]\n",
    "\n",
    "    # Count new trials\n",
    "    new_trials = df_week.shape[0]\n",
    "\n",
    "    print(f\"New trials last week ({week_info['year_week']}): {new_trials}\")\n",
    "\n",
    "    return new_trials\n",
    "\n",
    "\n",
    "new_trial_last_week = get_new_trial_last_week(sub_df, weeks_back=1)\n",
    "new_trial_prev_week = get_new_trial_last_week(sub_df, weeks_back=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New trials last week (2025-W21): 70\n",
      "New trials last week (2025-W20): 110\n"
     ]
    }
   ],
   "source": [
    "# how many trial this week\n",
    "def get_new_trial_last_week(df, weeks_back=1):\n",
    "    \"\"\"Count new trials started this week using pandas dt.isocalendar().week and year\"\"\"\n",
    "    df = df.copy()\n",
    "    # Ensure trial_start_utc is datetime\n",
    "    df['trial_start_utc'] = pd.to_datetime(df['trial_start_utc'])\n",
    "\n",
    "    # Get the current week and year\n",
    "    today = pd.to_datetime(today_date)\n",
    "    current_year, current_week = today.isocalendar().year, today.isocalendar().week\n",
    "\n",
    "    # Calculate the target week and year\n",
    "    # Subtract weeks_back from current week, handle year change\n",
    "    target_week = current_week - weeks_back\n",
    "    target_year = current_year\n",
    "    while target_week <= 0:\n",
    "        target_year -= 1\n",
    "        # Get the number of weeks in the previous year\n",
    "        last_year_weeks = pd.Timestamp(f\"{target_year}-12-28\").isocalendar().week\n",
    "        target_week += last_year_weeks\n",
    "\n",
    "    # Extract week and year from trial_start_utc\n",
    "    df['trial_year'] = df['trial_start_utc'].dt.isocalendar().year\n",
    "    df['trial_week'] = df['trial_start_utc'].dt.isocalendar().week\n",
    "\n",
    "    # Filter for the target week and year\n",
    "    df_week = df[(df['trial_year'] == target_year) & (df['trial_week'] == target_week)]\n",
    "\n",
    "    new_trials = df_week.shape[0]\n",
    "\n",
    "    print(f\"New trials last week ({target_year}-W{target_week}): {new_trials}\")\n",
    "\n",
    "    return new_trials\n",
    "\n",
    "new_trial_last_week = get_new_trial_last_week(sub_df, weeks_back=1)\n",
    "new_trial_prev_week = get_new_trial_last_week(sub_df, weeks_back=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trials: 17524, Full Members converted = 6585, Conversion rate: 37.58\n"
     ]
    }
   ],
   "source": [
    "# Count trials that converted to full members\n",
    "def get_conversion_rate(df):\n",
    "    \"\"\"Calculate conversion rate from trial to full member\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    new_customers = df[df['trial_start_utc'].notna()].copy()\n",
    "\n",
    "    mature_trials = new_customers[new_customers['refund_period_end_utc'] < today_date]\n",
    "\n",
    "    total_trials = len(mature_trials)\n",
    "    conversions = len(mature_trials[mature_trials['is_full_member'] == True])\n",
    "\n",
    "    conversion_rate = (conversions / total_trials * 100)\n",
    "\n",
    "\n",
    "    conversion_rate_dict = {\n",
    "        'total_trials': total_trials,\n",
    "        'mature_trials': mature_trials,\n",
    "        'conversion_rate': round(conversion_rate, 2)\n",
    "    }\n",
    "\n",
    "    print(f\"Total trials: {conversion_rate_dict['total_trials']}, Full Members converted = {conversions}, Conversion rate: {conversion_rate_dict['conversion_rate']}\")\n",
    "\n",
    "    return conversion_rate_dict\n",
    "\n",
    "\n",
    "conversion_rate_dict = get_conversion_rate(sub_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2c/jlpbrr154jg9cfp1pzbh8x5h0000gn/T/ipykernel_42981/2257096515.py:9: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  df['trial_week'] = df['trial_start_utc'].dt.week\n"
     ]
    }
   ],
   "source": [
    "# Count trials that converted to full members\n",
    "def get_conversion_rate(df):\n",
    "    \"\"\"Calculate conversion rate from trial to full member\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Use .dt.year and .dt.week for demonstration (though not strictly needed here)\n",
    "    if 'trial_start_utc' in df.columns and pd.api.types.is_datetime64_any_dtype(df['trial_start_utc']):\n",
    "        df['trial_year'] = df['trial_start_utc'].dt.year\n",
    "        df['trial_week'] = df['trial_start_utc'].dt.week\n",
    "\n",
    "    new_customers = df[df['trial_start_utc'].notna()].copy()\n",
    "\n",
    "    mature_trials = new_customers[new_customers['refund_period_end_utc'] < today_date]\n",
    "\n",
    "    total_trials = len(mature_trials)\n",
    "    conversions = len(mature_trials[mature_trials['is_full_member'] == True])\n",
    "\n",
    "    conversion_rate = (conversions / total_trials * 100) if total_trials > 0 else 0.0\n",
    "\n",
    "    conversion_rate_dict = {\n",
    "        'total_trials': total_trials,\n",
    "        'mature_trials': mature_trials,\n",
    "        'conversion_rate': round(conversion_rate, 2)\n",
    "    }\n",
    "\n",
    "    return conversion_rate_dict\n",
    "\n",
    "conversion_rate_dict = get_conversion_rate(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count trials that converted to full members\n",
    "def get_conversion_rate_last_week(df, weeks_back=1):\n",
    "    \"\"\"Calculate conversion rate from trial to full member\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    week_info = get_specific_past_week(weeks_back=weeks_back, reference_date=today_date)\n",
    "    # Filter for the current week\n",
    "    mature_customers = df[(df['refund_period_end_utc'] >= week_info['week_start']) &\n",
    "                          (df['refund_period_end_utc'] < week_info['week_end']) &\n",
    "                          (df['trial_start_utc'].notna())].copy()\n",
    "\n",
    "\n",
    "    total_trials = len(mature_customers)\n",
    "    conversions = len(mature_customers[mature_customers['is_full_member'] == True])\n",
    "\n",
    "    conversion_rate = (conversions / total_trials * 100)\n",
    "\n",
    "\n",
    "    return conversion_rate\n",
    "\n",
    "\n",
    "last_week_conversion_rate = get_conversion_rate_last_week(sub_df, weeks_back=1)\n",
    "prev_week_conversion_rate = get_conversion_rate_last_week(sub_df, weeks_back=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_full_members_last_week(df, today_date, weeks_back=1):\n",
    "    \"\"\"\n",
    "    Get new full members from last week\n",
    "    \"\"\"\n",
    "    week_info = get_specific_past_week(weeks_back=weeks_back, reference_date=today_date)\n",
    "\n",
    "    # New full members = those whose refund period ended last week\n",
    "    last_week_full_members = df[\n",
    "        (df['refund_period_end_utc'] >= week_info['week_start']) &\n",
    "        (df['refund_period_end_utc'] <= week_info['week_end']) &\n",
    "        (df['is_full_member'] == True)\n",
    "    ]\n",
    "\n",
    "    last_week_full_members = len(last_week_full_members)\n",
    "\n",
    "    return last_week_full_members\n",
    "\n",
    "last_week_full_members = get_new_full_members_last_week(sub_df, today_date, weeks_back=1)\n",
    "prev_week_full_members = get_new_full_members_last_week(sub_df, today_date, weeks_back=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_churn_members_last_week(df, today_date, weeks_back=1):\n",
    "    \"\"\"\n",
    "    Get churned members from last week (using the function from previous artifact)\n",
    "    \"\"\"\n",
    "    week_info = get_specific_past_week(weeks_back=weeks_back, reference_date=today_date)\n",
    "\n",
    "    # Churned members = those who canceled last week\n",
    "    churned_members = df[\n",
    "        (df['canceled_at_utc'] >= week_info['week_start']) &\n",
    "        (df['canceled_at_utc'] <= week_info['week_end']) &\n",
    "        (df['is_full_member'] == True)\n",
    "    ]\n",
    "\n",
    "    last_week_churned_members = len(churned_members)\n",
    "\n",
    "    return last_week_churned_members\n",
    "\n",
    "last_week_churned_members = get_churn_members_last_week(sub_df, today_date, weeks_back=1)\n",
    "prev_week_churned_members = get_churn_members_last_week(sub_df, today_date, weeks_back=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial customers who became full members: 7055\n",
      "conversion rate: 38.42%\n"
     ]
    }
   ],
   "source": [
    "def cus_renewal(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    df = df[~df['is_gifted_member']]\n",
    "\n",
    "    # number of customers who had trial\n",
    "    all_customers = df[df['created_utc'].notna()]\n",
    "\n",
    "    all_active_full_member = all_customers[~all_customers['is_gifted_member']]\n",
    "\n",
    "    # number of customers who became full members (from trial)\n",
    "    trial_to_full_member = all_customers[\n",
    "        (~all_customers['canceled_during_trial']) &\n",
    "        (~all_customers['canceled_during_refund_period']) &\n",
    "        (all_customers['paid_duration'] > 14) &\n",
    "        (~all_customers['is_gifted_member'])\n",
    "    ]\n",
    "\n",
    "    print(f\"trial customers who became full members: {len(trial_to_full_member)}\")\n",
    "\n",
    "    # trial > full member conversion rate\n",
    "    conversion_rate = (len(trial_to_full_member) / len(all_customers) * 100)\n",
    "    print(f\"conversion rate: {conversion_rate:.2f}%\")\n",
    "\n",
    "\n",
    "    # 1st year customers\n",
    "    customers_in_y1 = trial_to_full_member[trial_to_full_member['paid_duration'] <= 366]\n",
    "\n",
    "    # active in 1st year\n",
    "    active_in_y1 = customers_in_y1[customers_in_y1['status'] == 'active']\n",
    "\n",
    "    # chrun during 1st year\n",
    "    canceled_during_y1 = customers_in_y1[customers_in_y1['canceled_at_utc'].notna()]\n",
    "\n",
    "    # cancelation rate during y1\n",
    "    y1_cancelation_rate = (len(canceled_during_y1) / len(customers_in_y1) * 100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # customers eligible to year 2\n",
    "    eligible_for_y2 = trial_to_full_member[trial_to_full_member['paid_duration'] >= 364]\n",
    "\n",
    "    # customer currently in year 2\n",
    "    customers_in_y2 = eligible_for_y2[eligible_for_y2['paid_duration'] <= 730]\n",
    "\n",
    "    # currently active in y2\n",
    "    active_in_y2 = customers_in_y2[customers_in_y2['status'] == 'active']\n",
    "\n",
    "    # customer who renewed for a second year\n",
    "    renewed_to_y2 = eligible_for_y2[eligible_for_y2['paid_duration'] >= (364 + REFUND_PERIOD_DAYS)]\n",
    "    #renewed_to_y2 = eligible_for_y2[eligible_for_y2['is_full_member']]\n",
    "\n",
    "    # customer who canceled in year 2\n",
    "    canceled_during_y2 = customers_in_y2[customers_in_y2['canceled_at_utc'].notna()]\n",
    "\n",
    "    # renewal rate from y1 to y2\n",
    "    renewal_rate_y1_to_y2 = (len(renewed_to_y2) / len(eligible_for_y2) * 100)\n",
    "\n",
    "    # cancelation rate during y2\n",
    "    y2_cancelation_rate = (len(canceled_during_y2) / len(customers_in_y2) * 100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # customers eligible to year 3\n",
    "    eligible_for_y3 = trial_to_full_member[trial_to_full_member['paid_duration'] >= 729]\n",
    "\n",
    "    # customer currently in year 3\n",
    "    customers_in_y3 = trial_to_full_member[trial_to_full_member['paid_duration'] >= 729]\n",
    "\n",
    "    # currently active in y3\n",
    "    active_in_y3 = customers_in_y3[customers_in_y3['status'] == 'active']\n",
    "\n",
    "    # customer who renewed for a second year\n",
    "    renewed_to_y3 = eligible_for_y3[eligible_for_y3['paid_duration'] >= (729 + REFUND_PERIOD_DAYS)]\n",
    "\n",
    "    # customer who canceled in year 3\n",
    "    canceled_during_y3 = customers_in_y3[customers_in_y3['canceled_at_utc'].notna()]\n",
    "\n",
    "    # renewal rate from y2 to y3\n",
    "    renewal_rate_y2_to_y3 = (len(renewed_to_y3) / len(eligible_for_y3) * 100) if len(eligible_for_y3) > 0 else 0\n",
    "\n",
    "    # cancelation rate during y3\n",
    "    y3_cancelation_rate = (len(canceled_during_y3) / len(eligible_for_y3) * 100) if len(eligible_for_y3) > 0 else 0\n",
    "\n",
    "\n",
    "\n",
    "    renewal_dict = {\n",
    "        'all_customers_df' : all_customers,\n",
    "        'all_customer' : len(all_customers),\n",
    "\n",
    "        'all_active_full_member_df' : all_active_full_member,\n",
    "        'all_active_full_member' : len(all_active_full_member),\n",
    "\n",
    "        'trial_to_full_member_df' : trial_to_full_member,\n",
    "        'trial_to_full_member' : len(trial_to_full_member),\n",
    "\n",
    "        'conversion_rate' : conversion_rate,\n",
    "\n",
    "        'customers_in_y1_df' : customers_in_y1,\n",
    "        'customers_in_y1' : len(customers_in_y1),\n",
    "\n",
    "        'active_in_y1_df' : active_in_y1,\n",
    "        'active_in_y1' : len(active_in_y1),\n",
    "\n",
    "        'canceled_during_y1_df' : canceled_during_y1,\n",
    "        'canceled_during_y1' : len(canceled_during_y1),\n",
    "\n",
    "        'y1_cancelation_rate' : y1_cancelation_rate,\n",
    "\n",
    "        'eligible_for_y2_df' : eligible_for_y2,\n",
    "        'eligible_for_y2' : len(eligible_for_y2),\n",
    "\n",
    "        'customer_in_y2_df' : customers_in_y2,\n",
    "        'customer_in_y2' : len(customers_in_y2),\n",
    "\n",
    "        'active_in_y2_df' : active_in_y2,\n",
    "        'active_in_y2' : len(active_in_y2),\n",
    "\n",
    "        'renewed_to_y2_df' : renewed_to_y2,\n",
    "        'renewed_to_y2' : len(renewed_to_y2),\n",
    "\n",
    "        'canceled_during_y2_df' : canceled_during_y2,\n",
    "        'canceled_during_y2' : len(canceled_during_y2),\n",
    "\n",
    "        'y2_cancelation_rate' : y2_cancelation_rate,\n",
    "        'renewal_rate_y1_to_y2' : renewal_rate_y1_to_y2,\n",
    "\n",
    "        'eligible_for_y3_df' : eligible_for_y3,\n",
    "        'eligible_for_y3' : len(eligible_for_y3),\n",
    "\n",
    "        'customer_in_y3_df' : customers_in_y3,\n",
    "        'customer_in_y3' : len(customers_in_y3),\n",
    "\n",
    "        'active_in_y3_df' : active_in_y3,\n",
    "        'active_in_y3' : len(active_in_y3),\n",
    "\n",
    "        'renewed_to_y3_df' : renewed_to_y3,\n",
    "        'renewed_to_y3' : len(renewed_to_y3),\n",
    "\n",
    "        'canceled_during_y3_df' : canceled_during_y3,\n",
    "        'canceled_during_y3' : len(canceled_during_y3),\n",
    "\n",
    "        'y3_cancelation_rate' : y3_cancelation_rate,\n",
    "        'renewal_rate_y2_to_y3' : renewal_rate_y2_to_y3}\n",
    "\n",
    "    return renewal_dict\n",
    "\n",
    "\n",
    "renewal_dict = cus_renewal(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key, Value\n",
      "\n",
      "all_customer: 18361\n",
      "all_active_full_member: 18361\n",
      "trial_to_full_member: 7055\n",
      "conversion_rate: 38.42383312455749\n",
      "customers_in_y1: 5078\n",
      "active_in_y1: 3677\n",
      "canceled_during_y1: 1420\n",
      "y1_cancelation_rate: 27.96376526191414\n",
      "eligible_for_y2: 2955\n",
      "customer_in_y2: 2955\n",
      "active_in_y2: 1769\n",
      "renewed_to_y2: 1934\n",
      "canceled_during_y2: 1181\n",
      "y2_cancelation_rate: 39.96615905245347\n",
      "renewal_rate_y1_to_y2: 65.44839255499154\n",
      "eligible_for_y3: 0\n",
      "customer_in_y3: 0\n",
      "active_in_y3: 0\n",
      "renewed_to_y3: 0\n",
      "canceled_during_y3: 0\n",
      "y3_cancelation_rate: 0\n",
      "renewal_rate_y2_to_y3: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Key, Value\\n\")\n",
    "for key, value in renewal_dict.items():\n",
    "    if not key.endswith('_df'):\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4041314398.py, line 80)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[93], line 80\u001b[0;36m\u001b[0m\n\u001b[0;31m    Format dates for X axis\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def weekly_flow_all_time(cus_df, today_date):\n",
    "    \"\"\"\n",
    "    Create a dual-axis chart with weekly metrics for ALL TIME\n",
    "    North: Conversions + Renewals (stacked)\n",
    "    South: Churn full members\n",
    "    + Cumulative line plot\n",
    "    \"\"\"\n",
    "\n",
    "    renewal_dict = cus_renewal(cus_df)\n",
    "\n",
    "    all_customers_df = renewal_dict['all_customers_df']\n",
    "    trial_to_full_member_df = renewal_dict['trial_to_full_member_df']\n",
    "    customers_in_y1 = renewal_dict['customers_in_y1_df']\n",
    "    customer_in_y2 = renewal_dict['customer_in_y2_df']\n",
    "    customer_in_y3  = renewal_dict['customer_in_y3_df']\n",
    "    renewed_to_y2_df = renewal_dict['renewed_to_y2_df']\n",
    "    renewed_to_y3_df = renewal_dict['renewed_to_y3_df']\n",
    "\n",
    "\n",
    "    # Use all data since first date\n",
    "    first_date = cus_df['created_utc'].min()\n",
    "    num_weeks = int((today_date - first_date).days / 7) + 1\n",
    "    print(f\"Analysis since first date: {first_date.strftime('%d-%m-%Y')} ({num_weeks} weeks)\")\n",
    "\n",
    "    conversion_customers = trial_to_full_member_df\n",
    "\n",
    "    weekly_conversions = conversion_customers.groupby(\n",
    "        pd.Grouper(key='created_utc', freq='W-MON')).size()\n",
    "\n",
    "    y1_to_y2_customers = renewed_to_y2_df.copy()\n",
    "    y1_to_y2_customers['renewal_date'] = y1_to_y2_customers['current_period_start_utc']\n",
    "\n",
    "    weekly_renewals_y1 = y1_to_y2_customers.groupby(\n",
    "        pd.Grouper(key='renewal_date', freq='W-MON')).size()\n",
    "\n",
    "    y2_to_y3_customers = renewed_to_y3_df.copy()\n",
    "    y2_to_y3_customers['renewal_date'] = y2_to_y3_customers['current_period_start_utc']\n",
    "\n",
    "    weekly_renewals_y2 = y2_to_y3_customers.groupby(\n",
    "        pd.Grouper(key='renewal_date', freq='W-MON')).size()\n",
    "\n",
    "    churn_customers = trial_to_full_member_df[trial_to_full_member_df['canceled_at_utc'].notna()]\n",
    "\n",
    "    weekly_churn = churn_customers.groupby(\n",
    "        pd.Grouper(key='canceled_at_utc', freq='W-MON')).size()\n",
    "\n",
    "\n",
    "\n",
    "    all_dates = []\n",
    "    for series in [weekly_conversions, weekly_renewals_y1, weekly_renewals_y2, weekly_churn]:\n",
    "        if len(series) > 0:\n",
    "            all_dates.extend(series.index.tolist())\n",
    "\n",
    "    if not all_dates:\n",
    "        print(\"‚ùå No data found\")\n",
    "        return {}\n",
    "\n",
    "    start_date = min(all_dates)\n",
    "    end_date = max(all_dates)\n",
    "\n",
    "    full_date_range = pd.date_range(start=start_date, end=end_date, freq='W-MON')\n",
    "\n",
    "    x_pos = range(len(full_date_range))\n",
    "    week_labels = [f\"{date.strftime('%d-%m-%y')} > {(date + pd.Timedelta(days=6)).strftime('%d-%m-%y')}\"\n",
    "               for date in full_date_range]\n",
    "\n",
    "    # Reindex all series to same range (fill missing weeks with 0)\n",
    "    weekly_conversions = weekly_conversions.reindex(full_date_range, fill_value=0)\n",
    "    weekly_renewals_y1 = weekly_renewals_y1.reindex(full_date_range, fill_value=0)\n",
    "    weekly_renewals_y2 = weekly_renewals_y2.reindex(full_date_range, fill_value=0)\n",
    "    weekly_churn = weekly_churn.reindex(full_date_range, fill_value=0)\n",
    "\n",
    "    # Calculate net weekly change and cumulative\n",
    "    net_weekly = weekly_conversions + weekly_renewals_y1 + weekly_renewals_y2 - weekly_churn\n",
    "    net_cumulative = net_weekly.cumsum()\n",
    "\n",
    "       # === CREATE CHART - ALL TIME ===\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(22, 8))\n",
    "\n",
    "    Format dates for X axis\n",
    "    weeks_labels = [week_info['monday'] + ' > ' + week_info['sunday'] for week_info in week_data]\n",
    "    x_pos = range(len(week_range))\n",
    "\n",
    "    # === POSITIVE BARPLOT (NORTH) ===\n",
    "    ax.bar(x_pos, weekly_conversions, label='Conversions (Trial‚ÜíFull)', color='green')\n",
    "    ax.bar(x_pos, weekly_renewals_y1, bottom=weekly_conversions,label='Renewals Y1', color='lightgreen')\n",
    "    ax.bar(x_pos, weekly_renewals_y2, \\\n",
    "           bottom=weekly_conversions + weekly_renewals_y1, \\\n",
    "           label='Renewals Y2+', color='orange')\n",
    "\n",
    "    # === NEGATIVE BARPLOT (SOUTH) ===\n",
    "    ax.bar(x_pos, -weekly_churn, label='Churn Full Members', color='red')\n",
    "\n",
    "    # === CUMULATIVE LINE PLOT ===\n",
    "    ax_twin = ax.twinx()\n",
    "    ax_twin.plot(x_pos, net_cumulative, color='darkblue', linewidth=1, \\\n",
    "                 label='Net Cumulative (Gains - Losses)')\n",
    "\n",
    "    # === AXIS CONFIGURATION ===\n",
    "    ax.set_ylabel('Full Members per week\\n(Positive: Gains | Negative: Losses)',\n",
    "                  fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Weeks (Monday - Sunday)', fontsize=12, fontweight='bold')\n",
    "\n",
    "    for i, (conv, ren1, ren2, churn) in enumerate(zip(weekly_conversions, weekly_renewals_y1, weekly_renewals_y2, weekly_churn)):\n",
    "        total_gains = conv + ren1 + ren2\n",
    "        if total_gains > 0:\n",
    "            ax.text(i, total_gains + 0.5, str(int(total_gains)),\n",
    "                   ha='center', va='bottom', fontsize=7, color='darkgreen', fontweight='bold')\n",
    "\n",
    "        if churn > 0:\n",
    "            ax.text(i, -churn - 0.5, str(int(churn)),\n",
    "                   ha='center', va='top', fontsize=7, color='darkred')\n",
    "\n",
    "    ax_twin.set_ylabel('Net Cumulative Total', fontsize=12, fontweight='bold')\n",
    "    ax_twin.tick_params(axis='y', labelcolor='darkblue')\n",
    "\n",
    "    # === VISUAL CONFIGURATION ===\n",
    "    ax.axhline(y=0, color='black', linestyle='-', linewidth=1, alpha=0.5)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    ax.set_xlim(-0.3, len(x_pos) - 0.5)\n",
    "\n",
    "    # Adjust Y limits\n",
    "    y_max = max(weekly_conversions + weekly_renewals_y1 + weekly_renewals_y2) * 1.2\n",
    "    y_min = -max(weekly_churn) * 1.2\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "\n",
    "    # X axis configuration - reduce labels for long periods\n",
    "    step = max(1, len(x_pos) // 15)\n",
    "    ax.set_xticks(x_pos[::step])\n",
    "    ax.set_xticklabels([week_labels[i] for i in x_pos[::step]],\n",
    "                       rotation=45, ha='right', fontsize=9)\n",
    "\n",
    "\n",
    "    # === GREY ZONE FOR IMMATURE PERIODS ===\n",
    "    immature_cutoff = today_date - pd.Timedelta(days=24)  # Extended for customers\n",
    "    immature_weeks = [i for i, date in enumerate(full_date_range) if date >= immature_cutoff]\n",
    "\n",
    "    if immature_weeks:\n",
    "        start_idx = min(immature_weeks) - 0.5\n",
    "        end_idx = max(immature_weeks) + 0.5\n",
    "        ax.axvspan(start_idx, end_idx, alpha=0.15, color='gray',\n",
    "                   label='Immature Period (< 50 days)', zorder=0)\n",
    "        print(f\"üîç Immature period: {len(immature_weeks)} recent weeks\")\n",
    "\n",
    "\n",
    "\n",
    "    # === TITLES AND LEGENDS ===\n",
    "    period_text = f'(from {start_date} to {end_date})'\n",
    "    ax.set_title(f'WEEKLY FULL MEMBERS FLOW - ALL TIME\\n{period_text}', fontsize=18, fontweight='bold', pad=30)\n",
    "\n",
    "    # Combine legends\n",
    "    lines1, labels1 = ax.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax_twin.get_legend_handles_labels()\n",
    "    ax.legend(lines1 + lines2, labels1 + labels2, loc='best', fontsize=10)\n",
    "\n",
    "    # === SUMMARY METRICS ===\n",
    "    print(\"=== CALCULATING METRICS ===\")\n",
    "\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # === SAVE ===\n",
    "    filename = f\"weekly_flow_all_time_{today_date.strftime('%Y-%m-%d')}.png\"\n",
    "    plt.savefig(os.path.join(analysis_dir, filename), dpi=300, bbox_inches='tight')\n",
    "    print(f\"All time chart saved: {filename}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    print(weekly_churn, weekly_renewals_y2)\n",
    "\n",
    "weekly_flow_all_time(sub_df, today_date)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
